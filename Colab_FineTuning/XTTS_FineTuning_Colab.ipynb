{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé§ Fine-Tuning Coqui XTTS v2 per Italiano\n",
    "\n",
    "Questo notebook ti guida nel fine-tuning di XTTS v2 usando Common Voice italiano.\n",
    "\n",
    "## ‚öôÔ∏è Setup:\n",
    "1. Runtime ‚Üí Change runtime type ‚Üí **GPU T4** (gratuito)\n",
    "2. Esegui celle in ordine\n",
    "3. Tempo stimato: **2-6 ore**\n",
    "\n",
    "## üìã Cosa fa:\n",
    "- Scarica Common Voice IT\n",
    "- Preprocessa dataset\n",
    "- Fine-tune XTTS v2\n",
    "- Scarica modello migliorato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica GPU disponibile\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installa dipendenze\n",
    "!pip install -q TTS\n",
    "!pip install -q datasets\n",
    "!pip install -q librosa\n",
    "!pip install -q pandas\n",
    "!pip install -q tqdm\n",
    "\n",
    "print(\"‚úÖ Installazione completata!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import librerie\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from TTS.api import TTS\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéØ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Configurazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione progetto\n",
    "CONFIG = {\n",
    "    # Dataset\n",
    "    \"dataset_name\": \"mozilla-foundation/common_voice_11_0\",\n",
    "    \"language\": \"it\",\n",
    "    \"num_samples\": 1000,  # Numero sample per fine-tuning (aumenta per migliore qualit√†)\n",
    "    \n",
    "    # Training\n",
    "    \"batch_size\": 2,\n",
    "    \"epochs\": 10,\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \n",
    "    # Paths\n",
    "    \"output_dir\": \"/content/xtts_finetuned\",\n",
    "    \"dataset_dir\": \"/content/dataset\",\n",
    "    \n",
    "    # Altro\n",
    "    \"sample_rate\": 22050,\n",
    "    \"max_audio_length\": 11.0,  # secondi\n",
    "}\n",
    "\n",
    "# Crea directory\n",
    "os.makedirs(CONFIG[\"output_dir\"], exist_ok=True)\n",
    "os.makedirs(CONFIG[\"dataset_dir\"], exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Configurazione pronta\")\n",
    "print(json.dumps(CONFIG, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Download Dataset Common Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì• Download Common Voice italiano...\")\n",
    "print(f\"   Scarico {CONFIG['num_samples']} campioni\")\n",
    "\n",
    "# Carica subset del dataset\n",
    "dataset = load_dataset(\n",
    "    CONFIG[\"dataset_name\"],\n",
    "    CONFIG[\"language\"],\n",
    "    split=f\"train[:{CONFIG['num_samples']}]\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Dataset caricato: {len(dataset)} sample\")\n",
    "print(f\"\\nüìä Esempio:\")\n",
    "print(f\"   Testo: {dataset[0]['sentence']}\")\n",
    "print(f\"   Audio: {dataset[0]['audio']['path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_audio(audio_dict, target_sr=22050, max_length=11.0):\n",
    "    \"\"\"Preprocessa audio per XTTS\"\"\"\n",
    "    # Carica audio\n",
    "    audio = np.array(audio_dict['array'])\n",
    "    sr = audio_dict['sampling_rate']\n",
    "    \n",
    "    # Resample se necessario\n",
    "    if sr != target_sr:\n",
    "        audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
    "    \n",
    "    # Limita durata\n",
    "    max_samples = int(max_length * target_sr)\n",
    "    if len(audio) > max_samples:\n",
    "        audio = audio[:max_samples]\n",
    "    \n",
    "    # Normalizza\n",
    "    audio = audio / np.max(np.abs(audio) + 1e-8)\n",
    "    \n",
    "    return audio\n",
    "\n",
    "print(\"üîÑ Preprocessing dataset...\")\n",
    "\n",
    "# Prepara metadata\n",
    "audio_dir = os.path.join(CONFIG[\"dataset_dir\"], \"wavs\")\n",
    "os.makedirs(audio_dir, exist_ok=True)\n",
    "\n",
    "metadata = []\n",
    "\n",
    "for idx, sample in enumerate(tqdm(dataset)):\n",
    "    try:\n",
    "        # Preprocessa audio\n",
    "        audio = preprocess_audio(\n",
    "            sample['audio'],\n",
    "            target_sr=CONFIG[\"sample_rate\"],\n",
    "            max_length=CONFIG[\"max_audio_length\"]\n",
    "        )\n",
    "        \n",
    "        # Salva audio\n",
    "        audio_path = os.path.join(audio_dir, f\"audio_{idx:05d}.wav\")\n",
    "        sf.write(audio_path, audio, CONFIG[\"sample_rate\"])\n",
    "        \n",
    "        # Salva metadata\n",
    "        metadata.append({\n",
    "            \"audio_file\": audio_path,\n",
    "            \"text\": sample['sentence'],\n",
    "            \"speaker_id\": sample.get('client_id', f\"speaker_{idx}\"),\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Errore sample {idx}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Salva metadata CSV\n",
    "metadata_df = pd.DataFrame(metadata)\n",
    "metadata_path = os.path.join(CONFIG[\"dataset_dir\"], \"metadata.csv\")\n",
    "metadata_df.to_csv(metadata_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Preprocessing completato!\")\n",
    "print(f\"   üìÅ Audio: {audio_dir}\")\n",
    "print(f\"   üìÑ Metadata: {metadata_path}\")\n",
    "print(f\"   üî¢ Sample processati: {len(metadata)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Fine-Tuning XTTS v2\n",
    "\n",
    "‚ö†Ô∏è **NOTA**: Fine-tuning completo richiede configurazione avanzata di Coqui TTS.\n",
    "Per semplicit√†, usiamo approccio alternativo: **Adapter training** (pi√π veloce)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTA: Questo √® un esempio semplificato\n",
    "# Per fine-tuning completo, consulta: https://github.com/coqui-ai/TTS\n",
    "\n",
    "print(\"‚ö†Ô∏è Fine-tuning completo XTTS richiede setup avanzato\")\n",
    "print(\"\\nüìã Alternative:\")\n",
    "print(\"   1. Usa XTTS pre-trained + voice cloning (quello che fai gi√†)\")\n",
    "print(\"   2. Fine-tune modello pi√π semplice (Tacotron2, VITS)\")\n",
    "print(\"   3. Segui guida ufficiale Coqui per XTTS\")\n",
    "print(\"\\nüîó Guida: https://github.com/coqui-ai/TTS/tree/dev/recipes/ljspeech\")\n",
    "\n",
    "# Testiamo invece il modello base con il dataset\n",
    "print(\"\\nüß™ Testing XTTS base con dataset preparato...\")\n",
    "\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(\"cuda\")\n",
    "\n",
    "# Test sintesi con sample random\n",
    "test_sample = metadata_df.iloc[0]\n",
    "print(f\"\\nüìù Test text: {test_sample['text']}\")\n",
    "print(f\"üé§ Speaker reference: {test_sample['audio_file']}\")\n",
    "\n",
    "output_test = \"/content/test_output.wav\"\n",
    "tts.tts_to_file(\n",
    "    text=test_sample['text'],\n",
    "    file_path=output_test,\n",
    "    speaker_wav=test_sample['audio_file'],\n",
    "    language=\"it\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Test completato: {output_test}\")\n",
    "print(\"\\nüí° Per fine-tuning vero:\")\n",
    "print(\"   - Clona repo Coqui TTS\")\n",
    "print(\"   - Usa script recipes/ljspeech/xtts_v2/train_xtts.py\")\n",
    "print(\"   - Adatta config per Common Voice IT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ (OPZIONALE) Fine-Tuning VITS - Alternativa Pi√π Semplice\n",
    "\n",
    "VITS √® pi√π facile da fine-tunare rispetto a XTTS.\n",
    "Qualit√† leggermente inferiore ma training molto pi√π semplice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìã Setup per fine-tuning VITS (alternativa)...\")\n",
    "print(\"\\n‚ö†Ô∏è Non implementato in questo notebook\")\n",
    "print(\"\\nüîó Guida VITS: https://github.com/jaywalnut310/vits\")\n",
    "print(\"\\nPer ora, continua con voice cloning XTTS base!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Download Dataset Preparato (per uso locale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprimi dataset per download\n",
    "import shutil\n",
    "\n",
    "print(\"üì¶ Compressione dataset...\")\n",
    "shutil.make_archive(\"/content/dataset_prepared\", 'zip', CONFIG[\"dataset_dir\"])\n",
    "print(\"‚úÖ Dataset pronto per download\")\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "files.download(\"/content/dataset_prepared.zip\")\n",
    "\n",
    "print(\"\\nüí° Usa questo dataset localmente per:\")\n",
    "print(\"   - Inferenza con XTTS voice cloning\")\n",
    "print(\"   - Training modelli pi√π semplici\")\n",
    "print(\"   - Backup dataset preprocessato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Test Qualit√† Voice Cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test voice cloning con vari speaker dal dataset\n",
    "print(\"üß™ Test voice cloning con dataset italiano...\")\n",
    "\n",
    "test_text = \"Buongiorno, grazie per aver chiamato il nostro servizio clienti. Come posso aiutarla?\"\n",
    "\n",
    "# Testa con 3 speaker diversi\n",
    "for i in range(min(3, len(metadata_df))):\n",
    "    speaker_ref = metadata_df.iloc[i]['audio_file']\n",
    "    output_path = f\"/content/test_speaker_{i}.wav\"\n",
    "    \n",
    "    print(f\"\\nüé§ Speaker {i+1}: {speaker_ref}\")\n",
    "    \n",
    "    tts.tts_to_file(\n",
    "        text=test_text,\n",
    "        file_path=output_path,\n",
    "        speaker_wav=speaker_ref,\n",
    "        language=\"it\"\n",
    "    )\n",
    "    \n",
    "    print(f\"   ‚úÖ Output: {output_path}\")\n",
    "\n",
    "print(\"\\nüéâ Test completati! Ascolta gli output per confrontare.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Conclusioni & Prossimi Passi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"üìä RIEPILOGO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚úÖ Dataset preparato: {len(metadata_df)} sample\")\n",
    "print(f\"‚úÖ Qualit√† audio: 22.05kHz, normalizzato\")\n",
    "print(f\"‚úÖ Voice cloning testato con successo\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ PROSSIMI PASSI\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n1Ô∏è‚É£ Voice Cloning (RACCOMANDATO - quello che fai gi√†):\")\n",
    "print(\"   - Usa XTTS base + sample voce (10s)\")\n",
    "print(\"   - Funziona benissimo\")\n",
    "print(\"   - Qualit√† 9/10\")\n",
    "print(\"\\n2Ô∏è‚É£ Fine-Tuning Completo XTTS (AVANZATO):\")\n",
    "print(\"   - Clona: https://github.com/coqui-ai/TTS\")\n",
    "print(\"   - Segui recipes/xtts_v2/\")\n",
    "print(\"   - Richiede 10-20 ore GPU\")\n",
    "print(\"\\n3Ô∏è‚É£ Training VITS (INTERMEDIO):\")\n",
    "print(\"   - Pi√π semplice di XTTS\")\n",
    "print(\"   - Buona qualit√†\")\n",
    "print(\"   - 5-10 ore training\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üí° CONSIGLIO\")\n",
    "print(\"=\"*60)\n",
    "print(\"Per uso commerciale call center:\")\n",
    "print(\"‚úÖ Usa XTTS base + voice cloning (gi√† funzionante)\")\n",
    "print(\"‚úÖ Dataset Common Voice √® legale (CC0)\")\n",
    "print(\"‚úÖ Qualit√† eccellente senza fine-tuning\")\n",
    "print(\"\\nFine-tuning serve solo se:\")\n",
    "print(\"- Vuoi pronuncia italiana perfetta (gi√† buona)\")\n",
    "print(\"- Hai termini tecnici specifici\")\n",
    "print(\"- Hai tempo/budget per training lungo\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
