# üìä Dataset Italiani per TTS Training

Questa guida elenca i dataset disponibili per training di modelli TTS in italiano.

## üé§ Dataset LJSpeech-Italian

### Dataset Disponibili su Hugging Face:

#### 1. z-uo/female-LJSpeech-italian ‚≠ê CONSIGLIATO
- **Voce**: Femminile
- **Durata**: 8h 23m
- **Speaker**: 1 (voce singola)
- **Sample Rate**: 16kHz
- **Dimensione**: ~600 MB
- **Fonte**: M-AILABS Speech Dataset
- **Uso ideale**: Call center, assistenti vocali, applicazioni commerciali
- **Link**: https://huggingface.co/datasets/z-uo/female-LJSpeech-italian

```python
from datasets import load_dataset
dataset = load_dataset("z-uo/female-LJSpeech-italian", split="train")
```

#### 2. z-uo/male-LJSpeech-italian
- **Voce**: Maschile
- **Durata**: 31h 45m
- **Speaker**: 1 (voce singola)
- **Sample Rate**: 16kHz
- **Dimensione**: ~2.5 GB
- **Fonte**: M-AILABS Speech Dataset
- **Uso ideale**: Training esteso, alta qualit√†
- **Link**: https://huggingface.co/datasets/z-uo/male-LJSpeech-italian

```python
from datasets import load_dataset
dataset = load_dataset("z-uo/male-LJSpeech-italian", split="train")
```

---

## üóÇÔ∏è Altri Dataset Italiani Disponibili

### Common Voice

#### sarulab-speech/commonvoice22_sidon
- **Tipo**: Multi-speaker
- **Lingua**: Italiano (e altre)
- **Variabilit√†**: Alta (molti speaker diversi)
- **Uso**: Training robusto multi-speaker

### LibriSpeech

#### facebook/multilingual_librispeech
- **Tipo**: Multi-speaker
- **Lingue**: Multiple (include italiano)
- **Qualit√†**: Alta
- **Uso**: Training multi-lingue

### Dataset Specializzati

#### giacomoarienti/female-LJSpeech-italian
- **Nota**: Potrebbe essere rinominato o non pi√π disponibile
- **Alternativa**: Usa `z-uo/female-LJSpeech-italian`

#### None1145/Vulpisfoglia
- **Tipo**: Dataset specifico italiano
- **Verifica disponibilit√†** prima dell'uso

---

## üì• Come Scaricare e Usare

### Metodo 1: Script Python (Locale)

```bash
python scripts/download_ljspeech_italian.py \
  --dataset z-uo/female-LJSpeech-italian \
  --output-dir ./dataset/ljspeech_italian
```

**Opzioni disponibili**:
- `--dataset`: Scegli tra `z-uo/female-LJSpeech-italian` o `z-uo/male-LJSpeech-italian`
- `--output-dir`: Percorso di destinazione

### Metodo 2: Google Colab Notebook

1. Apri `Colab_FineTuning/Piper_Dataset_Preparation.ipynb`
2. Carica su Google Colab
3. Scegli dataset (female/male) nella cella
4. Esegui tutte le celle

### Metodo 3: Codice Python Diretto

```python
from datasets import load_dataset
import soundfile as sf
import os

# Scarica dataset
dataset = load_dataset("z-uo/female-LJSpeech-italian", split="train")

# Salva audio
for idx, item in enumerate(dataset):
    audio_data = item['audio']
    text = item['text']

    # Salva file audio
    sf.write(f"audio_{idx:06d}.wav",
             audio_data['array'],
             audio_data['sampling_rate'])

    print(f"{idx}: {text}")
```

---

## üîß Troubleshooting

### Errore: `ImportError: To support decoding audio data, please install 'torchcodec'`

**Soluzione**:
```bash
pip install torchcodec
```

Oppure usa il codice auto-installante:
```python
try:
    import torchcodec
except ImportError:
    !pip install -q torchcodec
```

### Errore: `DatasetNotFoundError: Dataset '...' doesn't exist`

**Causa**: Nome dataset errato

**Verifica nomi corretti**:
- ‚úÖ `z-uo/female-LJSpeech-italian`
- ‚úÖ `z-uo/male-LJSpeech-italian`
- ‚ùå `sololabs/ljspeech-italian` (non esiste)
- ‚ùå `giacomoarienti/...` (potrebbe essere rinominato)

### Dataset troppo grande per Colab

**Per dataset male (31h)**:
- Filtra subset: `split="train[:1000]"` (primi 1000 sample)
- Usa dataset female (pi√π piccolo)
- Scarica localmente invece che su Colab

---

## üìã Formato Dataset

Tutti i dataset seguono questo formato:

### Struttura File:
```
dataset/
‚îú‚îÄ‚îÄ wavs/
‚îÇ   ‚îú‚îÄ‚îÄ LJ_000000.wav
‚îÇ   ‚îú‚îÄ‚îÄ LJ_000001.wav
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ metadata.csv
```

### Formato metadata.csv:
```
LJ_000000.wav|Testo della prima frase.
LJ_000001.wav|Testo della seconda frase.
...
```

**Separatore**: `|` (pipe)
**Colonne**: `filename|text`
**Encoding**: UTF-8

---

## üéØ Quale Dataset Scegliere?

### Per Call Center / Assistenti Vocali:
‚úÖ **z-uo/female-LJSpeech-italian**
- Voce professionale
- Dimensione gestibile
- Qualit√† eccellente
- Tempo training ragionevole

### Per Ricerca / Massima Qualit√†:
‚úÖ **z-uo/male-LJSpeech-italian**
- Pi√π ore di training
- Qualit√† superiore
- Richiede pi√π tempo/GPU

### Per Variabilit√† Multi-Speaker:
‚úÖ **sarulab-speech/commonvoice22_sidon**
- Molti speaker diversi
- Accenti variati
- Robustezza maggiore

---

## üìö Risorse Aggiuntive

- **Piper TTS**: https://github.com/rhasspy/piper
- **Coqui TTS**: https://github.com/coqui-ai/TTS
- **Hugging Face Audio Datasets**: https://huggingface.co/datasets?task_categories=task_categories:text-to-speech
- **M-AILABS Dataset**: http://www.caito.de/2019/01/the-m-ailabs-speech-dataset/

---

## ‚öñÔ∏è Licenze

- **z-uo datasets**: Derivati da M-AILABS (verifica licenza originale)
- **Common Voice**: CC0 (pubblico dominio)
- **MultilinguaLibriSpeech**: CC BY 4.0

‚ö†Ô∏è **IMPORTANTE**: Verifica sempre la licenza prima dell'uso commerciale!

---

## üÜò Supporto

Problemi o domande? Apri una issue su GitHub o consulta:
- Script: `scripts/download_ljspeech_italian.py`
- Notebook: `Colab_FineTuning/Piper_Dataset_Preparation.ipynb`
- Documentazione Piper: https://github.com/rhasspy/piper
