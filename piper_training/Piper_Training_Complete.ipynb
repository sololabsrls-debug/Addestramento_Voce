{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé§ Piper TTS - Training Completo da Zero\n",
    "\n",
    "## üìã Panoramica\n",
    "Questo notebook permette di addestrare un modello Piper TTS completamente da zero.\n",
    "\n",
    "**Differenze con Fine-Tuning:**\n",
    "- ‚úÖ Training completo: crei un nuovo modello da zero\n",
    "- ‚úÖ Massimo controllo su architettura e hyperparameters\n",
    "- ‚úÖ Ideale per lingue/accenti non supportati\n",
    "- ‚è±Ô∏è Tempo: ~12-16 ore (vs 8-12h del fine-tuning)\n",
    "\n",
    "**Requisiti:**\n",
    "- Google Colab con GPU (T4 o superiore)\n",
    "- Dataset audio pulito (min 30 minuti, consigliato 2+ ore)\n",
    "- File di trascrizione accurati\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 1: Setup Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica GPU\n",
    "!nvidia-smi\n",
    "\n",
    "print(\"\\n‚úÖ Se vedi info GPU sopra, sei pronto!\")\n",
    "print(\"‚ùå Se errore: Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installazione dipendenze\n",
    "print(\"üì¶ Installazione Piper Training...\")\n",
    "\n",
    "!pip install -q piper-phonemize\n",
    "!pip install -q onnxruntime\n",
    "!pip install -q espeak-ng\n",
    "\n",
    "# Clona repository Piper\n",
    "!git clone https://github.com/rhasspy/piper.git\n",
    "%cd piper/src/python\n",
    "\n",
    "# Installa requirements\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q -e .\n",
    "\n",
    "%cd /content\n",
    "print(\"\\n‚úÖ Installazione completata!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ Step 2: Preparazione Dataset\n",
    "\n",
    "### Struttura Dataset Richiesta:\n",
    "```\n",
    "my_dataset/\n",
    "‚îú‚îÄ‚îÄ wavs/              # File audio WAV (16kHz, mono)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ audio_001.wav\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ audio_002.wav\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îî‚îÄ‚îÄ metadata.csv       # Trascrizioni\n",
    "```\n",
    "\n",
    "### Formato metadata.csv:\n",
    "```\n",
    "audio_001|Questa √® la prima frase.\n",
    "audio_002|Questa √® la seconda frase.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monta Google Drive (se il dataset √® l√¨)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Oppure carica manualmente i file\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura percorsi\n",
    "DATASET_DIR = \"/content/drive/MyDrive/my_dataset\"  # ‚ö†Ô∏è MODIFICA QUI\n",
    "OUTPUT_DIR = \"/content/piper_output\"\n",
    "\n",
    "!mkdir -p {OUTPUT_DIR}\n",
    "\n",
    "# Verifica dataset\n",
    "import os\n",
    "\n",
    "assert os.path.exists(DATASET_DIR), f\"‚ùå Dataset non trovato in {DATASET_DIR}\"\n",
    "assert os.path.exists(f\"{DATASET_DIR}/metadata.csv\"), \"‚ùå metadata.csv mancante\"\n",
    "assert os.path.exists(f\"{DATASET_DIR}/wavs\"), \"‚ùå Cartella wavs/ mancante\"\n",
    "\n",
    "# Conta file audio\n",
    "num_wavs = len([f for f in os.listdir(f\"{DATASET_DIR}/wavs\") if f.endswith('.wav')])\n",
    "print(f\"\\n‚úÖ Dataset trovato: {num_wavs} file audio\")\n",
    "\n",
    "if num_wavs < 100:\n",
    "    print(\"‚ö†Ô∏è Warning: Pochi file audio. Consigliati almeno 500-1000 per buoni risultati.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 3: Validazione Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verifica formato audio\nimport librosa\nimport pandas as pd\n\n# Carica metadata\nmetadata = pd.read_csv(f\"{DATASET_DIR}/metadata.csv\", \n                       sep='|', \n                       header=None, \n                       names=['filename', 'text'])\n\nprint(f\"üìä Statistiche Dataset:\")\nprint(f\"   Totale frasi: {len(metadata)}\")\nprint(f\"   Lunghezza media testo: {metadata['text'].str.len().mean():.0f} caratteri\")\n\n# Verifica alcuni file audio\nsample_files = metadata['filename'].head(5).tolist()\n\nfor fname in sample_files:\n    wav_path = f\"{DATASET_DIR}/wavs/{fname}.wav\"\n    if os.path.exists(wav_path):\n        y, sr = librosa.load(wav_path, sr=None)\n        duration = len(y) / sr\n        print(f\"   {fname}: {sr}Hz, {duration:.2f}s\")\n        \n        if sr != 16000:\n            print(f\"      ‚ö†Ô∏è Sample rate non ottimale. Consigliato: 16000Hz\")\n    else:\n        print(f\"   ‚ùå File mancante: {wav_path}\")\n\nprint(\"\\n‚úÖ Validazione completata!\")"
  },
  {
   "cell_type": "code",
   "source": "# Verifica COMPLETA del metadata.csv\nimport pandas as pd\nimport re\nfrom pathlib import Path\n\nprint(\"üîç Verifica metadata.csv in corso...\\n\")\n\nmetadata_path = f\"{DATASET_DIR}/metadata.csv\"\nwavs_dir = Path(f\"{DATASET_DIR}/wavs\")\n\n# Carica metadata\ntry:\n    metadata = pd.read_csv(metadata_path, sep='|', header=None, names=['filename', 'text'])\n    print(f\"‚úÖ File caricato: {len(metadata)} righe\\n\")\nexcept Exception as e:\n    print(f\"‚ùå ERRORE nel caricamento: {e}\")\n    raise\n\n# === VERIFICA 1: Formato righe ===\nprint(\"=\"*60)\nprint(\"1Ô∏è‚É£ VERIFICA FORMATO RIGHE\")\nprint(\"=\"*60)\n\ninvalid_rows = []\nfor idx, row in metadata.iterrows():\n    # Verifica che ci siano esattamente 2 colonne\n    if pd.isna(row['filename']) or pd.isna(row['text']):\n        invalid_rows.append(f\"Riga {idx+1}: Manca filename o text\")\n    # Verifica che filename non contenga caratteri strani\n    elif not re.match(r'^[a-zA-Z0-9_-]+$', str(row['filename'])):\n        invalid_rows.append(f\"Riga {idx+1}: Filename '{row['filename']}' contiene caratteri non validi\")\n    # Verifica che text non sia vuoto\n    elif len(str(row['text']).strip()) == 0:\n        invalid_rows.append(f\"Riga {idx+1}: Testo vuoto per '{row['filename']}'\")\n\nif invalid_rows:\n    print(f\"‚ùå Trovate {len(invalid_rows)} righe con formato non valido:\")\n    for err in invalid_rows[:5]:\n        print(f\"   ‚Ä¢ {err}\")\n    if len(invalid_rows) > 5:\n        print(f\"   ... e altre {len(invalid_rows)-5} righe\")\nelse:\n    print(\"‚úÖ Tutte le righe hanno formato corretto\")\n\n# === VERIFICA 2: Corrispondenza con file WAV ===\nprint(\"\\n\" + \"=\"*60)\nprint(\"2Ô∏è‚É£ VERIFICA CORRISPONDENZA FILE WAV\")\nprint(\"=\"*60)\n\n# File menzionati in metadata\nmetadata_files = set(metadata['filename'].astype(str))\n# File realmente presenti (senza estensione)\nactual_files = set(f.stem for f in wavs_dir.glob(\"*.wav\"))\n\n# File in metadata ma non in wavs/\nmissing_wavs = metadata_files - actual_files\n# File in wavs/ ma non in metadata\nextra_wavs = actual_files - metadata_files\n\nprint(f\"   File in metadata: {len(metadata_files)}\")\nprint(f\"   File in wavs/: {len(actual_files)}\")\n\nif missing_wavs:\n    print(f\"\\n‚ùå {len(missing_wavs)} file citati in metadata ma MANCANTI in wavs/:\")\n    for f in list(missing_wavs)[:5]:\n        print(f\"   ‚Ä¢ {f}.wav\")\n    if len(missing_wavs) > 5:\n        print(f\"   ... e altri {len(missing_wavs)-5} file\")\n\nif extra_wavs:\n    print(f\"\\n‚ö†Ô∏è {len(extra_wavs)} file in wavs/ ma NON citati in metadata:\")\n    for f in list(extra_wavs)[:5]:\n        print(f\"   ‚Ä¢ {f}.wav\")\n    if len(extra_wavs) > 5:\n        print(f\"   ... e altri {len(extra_wavs)-5} file\")\n\nif not missing_wavs and not extra_wavs:\n    print(\"\\n‚úÖ Perfetta corrispondenza! Tutti i file sono allineati.\")\n\n# === VERIFICA 3: Statistiche testo ===\nprint(\"\\n\" + \"=\"*60)\nprint(\"3Ô∏è‚É£ STATISTICHE TRASCRIZIONI\")\nprint(\"=\"*60)\n\ntext_lengths = metadata['text'].str.len()\nprint(f\"   Lunghezza media: {text_lengths.mean():.1f} caratteri\")\nprint(f\"   Lunghezza min: {text_lengths.min()} caratteri\")\nprint(f\"   Lunghezza max: {text_lengths.max()} caratteri\")\n\n# Verifica trascrizioni troppo corte o troppo lunghe\ntoo_short = metadata[text_lengths < 10]\ntoo_long = metadata[text_lengths > 500]\n\nif len(too_short) > 0:\n    print(f\"\\n‚ö†Ô∏è {len(too_short)} trascrizioni troppo corte (<10 caratteri):\")\n    for _, row in too_short.head(3).iterrows():\n        print(f\"   ‚Ä¢ {row['filename']}: '{row['text']}'\")\n\nif len(too_long) > 0:\n    print(f\"\\n‚ö†Ô∏è {len(too_long)} trascrizioni molto lunghe (>500 caratteri):\")\n    for _, row in too_long.head(3).iterrows():\n        print(f\"   ‚Ä¢ {row['filename']}: {len(row['text'])} caratteri\")\n\n# === VERIFICA 4: Duplicati ===\nprint(\"\\n\" + \"=\"*60)\nprint(\"4Ô∏è‚É£ VERIFICA DUPLICATI\")\nprint(\"=\"*60)\n\nduplicate_files = metadata[metadata.duplicated(subset=['filename'], keep=False)]\nif len(duplicate_files) > 0:\n    print(f\"‚ùå Trovati {len(duplicate_files)} filename duplicati:\")\n    print(duplicate_files[['filename']].drop_duplicates())\nelse:\n    print(\"‚úÖ Nessun filename duplicato\")\n\n# === RIEPILOGO FINALE ===\nprint(\"\\n\" + \"=\"*60)\nprint(\"üìä RIEPILOGO FINALE\")\nprint(\"=\"*60)\n\nissues_count = len(invalid_rows) + len(missing_wavs) + len(duplicate_files)\n\nif issues_count == 0 and len(extra_wavs) == 0:\n    print(\"üéâ TUTTO PERFETTO! Il metadata.csv √® correttamente formattato!\")\n    print(f\"   ‚úì {len(metadata)} righe valide\")\n    print(f\"   ‚úì Corrispondenza perfetta con i file WAV\")\n    print(f\"   ‚úì Nessun duplicato\")\n    print(\"\\n‚úÖ Sei pronto per il training!\")\nelse:\n    print(f\"‚ö†Ô∏è Trovati {issues_count} problemi che DEVONO essere risolti:\")\n    if invalid_rows:\n        print(f\"   ‚Ä¢ {len(invalid_rows)} righe con formato errato\")\n    if missing_wavs:\n        print(f\"   ‚Ä¢ {len(missing_wavs)} file WAV mancanti\")\n    if duplicate_files:\n        print(f\"   ‚Ä¢ {len(duplicate_files)} filename duplicati\")\n    if extra_wavs:\n        print(f\"\\n‚ö†Ô∏è Nota: {len(extra_wavs)} file WAV extra (non bloccante)\")\n    \n    print(\"\\nüîß Correggi questi problemi prima di procedere con il training!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ‚úÖ Step 3.2: Verifica Formato metadata.csv\n\nQuesta cella verifica che il metadata.csv sia correttamente formattato:\n- **Formato**: `filename|transcription`\n- **Separatore**: pipe `|`\n- **Encoding**: UTF-8\n- **Corrispondenza**: tutti i file citati esistono in wavs/",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Verifica COMPLETA di tutti i file WAV\nimport wave\nimport os\nfrom pathlib import Path\n\nprint(\"üîç Verifica formato audio in corso...\\n\")\n\nwavs_dir = Path(f\"{DATASET_DIR}/wavs\")\nwav_files = list(wavs_dir.glob(\"*.wav\"))\n\n# Contatori\ntotal_files = len(wav_files)\ncorrect_files = 0\nerrors = []\n\n# Requisiti Piper\nREQUIRED_SAMPLE_RATE = 16000\nREQUIRED_CHANNELS = 1  # Mono\nREQUIRED_SAMPWIDTH = 2  # 16-bit = 2 bytes\n\nprint(f\"üìä Analizzando {total_files} file WAV...\\n\")\n\nfor i, wav_path in enumerate(wav_files, 1):\n    try:\n        with wave.open(str(wav_path), 'rb') as wav:\n            sample_rate = wav.getframerate()\n            channels = wav.getnchannels()\n            sampwidth = wav.getsampwidth()\n            \n            # Verifica requisiti\n            is_correct = (\n                sample_rate == REQUIRED_SAMPLE_RATE and\n                channels == REQUIRED_CHANNELS and\n                sampwidth == REQUIRED_SAMPWIDTH\n            )\n            \n            if is_correct:\n                correct_files += 1\n            else:\n                error_msg = f\"{wav_path.name}: \"\n                issues = []\n                \n                if sample_rate != REQUIRED_SAMPLE_RATE:\n                    issues.append(f\"SR={sample_rate}Hz (richiesto {REQUIRED_SAMPLE_RATE}Hz)\")\n                if channels != REQUIRED_CHANNELS:\n                    issues.append(f\"Canali={channels} (richiesto {REQUIRED_CHANNELS})\")\n                if sampwidth != REQUIRED_SAMPWIDTH:\n                    issues.append(f\"Bit={sampwidth*8}-bit (richiesto 16-bit)\")\n                \n                error_msg += \", \".join(issues)\n                errors.append(error_msg)\n    \n    except Exception as e:\n        errors.append(f\"{wav_path.name}: ERRORE - {str(e)}\")\n    \n    # Progress bar\n    if i % 100 == 0 or i == total_files:\n        print(f\"   Progresso: {i}/{total_files} ({i*100//total_files}%)\")\n\n# Risultati\nprint(\"\\n\" + \"=\"*60)\nprint(\"üìä RISULTATI VERIFICA AUDIO:\")\nprint(\"=\"*60)\nprint(f\"‚úÖ File corretti: {correct_files}/{total_files} ({correct_files*100//total_files}%)\")\nprint(f\"‚ùå File con problemi: {len(errors)}\")\n\nif errors:\n    print(\"\\n‚ö†Ô∏è PROBLEMI RILEVATI:\")\n    print(\"-\"*60)\n    for error in errors[:10]:  # Mostra primi 10\n        print(f\"   ‚Ä¢ {error}\")\n    \n    if len(errors) > 10:\n        print(f\"   ... e altri {len(errors)-10} file con problemi\")\n    \n    print(\"\\nüí° SOLUZIONE: Converti i file usando ffmpeg:\")\n    print(\"   for f in wavs/*.wav; do\")\n    print(f\"       ffmpeg -i \\\"$f\\\" -ar {REQUIRED_SAMPLE_RATE} -ac {REQUIRED_CHANNELS} -sample_fmt s16 \\\"converted/${{f##*/}}\\\"\")\n    print(\"   done\")\nelse:\n    print(\"\\nüéâ PERFETTO! Tutti i file audio sono nel formato corretto!\")\n    print(f\"   ‚úì Sample rate: {REQUIRED_SAMPLE_RATE} Hz\")\n    print(f\"   ‚úì Canali: Mono\")\n    print(f\"   ‚úì Bit depth: 16-bit\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ‚úÖ Step 3.1: Verifica Rigorosa Formato Audio\n\nQuesta cella verifica che **TUTTI** i file WAV rispettino i requisiti Piper:\n- **Sample rate**: 22050 Hz\n- **Canali**: Mono (1 canale)\n- **Bit depth**: 16-bit",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Step 4: Configurazione Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Crea file di configurazione\nimport json\n\nconfig = {\n    \"audio\": {\n        \"sample_rate\": 16000,\n        \"max_wav_value\": 32767.0,\n        \"filter_length\": 1024,\n        \"hop_length\": 256,\n        \"win_length\": 1024\n    },\n    \"model\": {\n        \"name\": \"vits\",\n        \"hidden_channels\": 192,\n        \"inter_channels\": 192,\n        \"filter_channels\": 768,\n        \"n_heads\": 2,\n        \"n_layers\": 6,\n        \"kernel_size\": 3,\n        \"p_dropout\": 0.1\n    },\n    \"training\": {\n        \"epochs\": 10000,\n        \"learning_rate\": 0.0002,\n        \"batch_size\": 16,\n        \"log_interval\": 100,\n        \"save_interval\": 1000,\n        \"num_workers\": 4\n    },\n    \"dataset\": {\n        \"path\": DATASET_DIR,\n        \"text_cleaners\": [\"english_cleaners\"],  # ‚ö†Ô∏è Modifica per la tua lingua\n        \"language\": \"en-us\"  # ‚ö†Ô∏è Modifica codice lingua\n    }\n}\n\n# Salva configurazione\nconfig_path = f\"{OUTPUT_DIR}/config.json\"\nwith open(config_path, 'w') as f:\n    json.dump(config, f, indent=2)\n\nprint(f\"‚úÖ Configurazione salvata in {config_path}\")\nprint(\"\\nüìù Parametri principali:\")\nprint(f\"   - Epochs: {config['training']['epochs']}\")\nprint(f\"   - Batch size: {config['training']['batch_size']}\")\nprint(f\"   - Learning rate: {config['training']['learning_rate']}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 5: Avvio Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing del dataset\n",
    "print(\"üîÑ Preprocessing dataset...\")\n",
    "\n",
    "!python /content/piper/src/python/piper_train/preprocess.py \\\n",
    "    --input-dir {DATASET_DIR} \\\n",
    "    --output-dir {OUTPUT_DIR}/preprocessed \\\n",
    "    --language {config['dataset']['language']} \\\n",
    "    --sample-rate {config['audio']['sample_rate']}\n",
    "\n",
    "print(\"\\n‚úÖ Preprocessing completato!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training (questo richieder√† diverse ore)\n",
    "print(\"üéØ Avvio training... (questo richieder√† 12-16 ore)\")\n",
    "print(\"üí° Puoi monitorare i progressi nel log sotto.\\n\")\n",
    "\n",
    "%cd /content/piper/src/python\n",
    "\n",
    "!python -m piper_train \\\n",
    "    --dataset-dir {OUTPUT_DIR}/preprocessed \\\n",
    "    --output-dir {OUTPUT_DIR}/checkpoints \\\n",
    "    --config {config_path} \\\n",
    "    --restore-checkpoint  # Riprende da ultimo checkpoint se interrotto\n",
    "\n",
    "%cd /content\n",
    "print(\"\\nüéâ Training completato!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 6: Monitoraggio Training (Opzionale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizza ultimi checkpoint\n",
    "import glob\n",
    "\n",
    "checkpoints = sorted(glob.glob(f\"{OUTPUT_DIR}/checkpoints/*.pt\"))\n",
    "print(f\"üìÅ Checkpoint trovati: {len(checkpoints)}\\n\")\n",
    "\n",
    "for ckpt in checkpoints[-5:]:  # Ultimi 5\n",
    "    size_mb = os.path.getsize(ckpt) / (1024*1024)\n",
    "    print(f\"   {os.path.basename(ckpt)} ({size_mb:.1f}MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéµ Step 7: Export Modello Finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converti checkpoint PyTorch in ONNX (formato Piper)\n",
    "print(\"üì¶ Export modello in formato ONNX...\")\n",
    "\n",
    "# Trova ultimo checkpoint\n",
    "latest_checkpoint = sorted(glob.glob(f\"{OUTPUT_DIR}/checkpoints/*.pt\"))[-1]\n",
    "print(f\"   Usando: {os.path.basename(latest_checkpoint)}\")\n",
    "\n",
    "%cd /content/piper/src/python\n",
    "\n",
    "!python -m piper_train.export_onnx \\\n",
    "    {latest_checkpoint} \\\n",
    "    {OUTPUT_DIR}/model.onnx\n",
    "\n",
    "%cd /content\n",
    "print(\"\\n‚úÖ Modello esportato: model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Step 8: Test Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sintetizzazione\n",
    "from IPython.display import Audio\n",
    "import subprocess\n",
    "\n",
    "test_text = \"Questo √® un test del modello addestrato.\"  # ‚ö†Ô∏è Modifica testo\n",
    "output_wav = f\"{OUTPUT_DIR}/test_output.wav\"\n",
    "\n",
    "print(f\"üé§ Sintetizzo: '{test_text}'...\\n\")\n",
    "\n",
    "# Usa Piper per generare audio\n",
    "cmd = [\n",
    "    \"piper\",\n",
    "    \"--model\", f\"{OUTPUT_DIR}/model.onnx\",\n",
    "    \"--output_file\", output_wav\n",
    "]\n",
    "\n",
    "subprocess.run(cmd, input=test_text.encode('utf-8'))\n",
    "\n",
    "print(\"‚úÖ Audio generato! Ascolta sotto:\\n\")\n",
    "Audio(output_wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 9: Download Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea archivio con modello e config\n",
    "import shutil\n",
    "\n",
    "print(\"üì¶ Creazione archivio finale...\\n\")\n",
    "\n",
    "# Copia file necessari\n",
    "model_package = f\"{OUTPUT_DIR}/my_piper_model\"\n",
    "!mkdir -p {model_package}\n",
    "\n",
    "shutil.copy(f\"{OUTPUT_DIR}/model.onnx\", model_package)\n",
    "shutil.copy(config_path, model_package)\n",
    "\n",
    "# Crea archivio ZIP\n",
    "shutil.make_archive(model_package, 'zip', model_package)\n",
    "\n",
    "print(f\"‚úÖ Modello pronto per il download!\")\n",
    "print(f\"   Percorso: {model_package}.zip\\n\")\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "files.download(f\"{model_package}.zip\")\n",
    "\n",
    "print(\"\\nüéâ Training completato con successo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Note Finali\n",
    "\n",
    "### Prossimi Passi:\n",
    "1. **Fine-Tuning**: Puoi ora usare questo modello come base per ulteriore fine-tuning\n",
    "2. **Testing**: Prova il modello con frasi diverse per valutare la qualit√†\n",
    "3. **Ottimizzazione**: Se i risultati non sono ottimali:\n",
    "   - Aumenta il dataset (pi√π audio = migliori risultati)\n",
    "   - Aumenta epochs\n",
    "   - Modifica learning rate\n",
    "\n",
    "### Troubleshooting:\n",
    "- **OOM (Out of Memory)**: Riduci batch_size nel config\n",
    "- **Audio distorto**: Verifica che tutti i WAV siano 22050Hz mono\n",
    "- **Training lento**: Assicurati di usare GPU T4 o superiore\n",
    "\n",
    "### Risorse:\n",
    "- üìñ [Piper Documentation](https://github.com/rhasspy/piper)\n",
    "- üí¨ [Piper Discussion](https://github.com/rhasspy/piper/discussions)\n",
    "\n",
    "---\n",
    "\n",
    "**Buon training! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}