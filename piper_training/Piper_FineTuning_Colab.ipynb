{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéôÔ∏è Piper TTS - Fine-Tuning Completo\n",
    "\n",
    "Notebook completo per fine-tuning di modelli Piper TTS su Google Colab.\n",
    "\n",
    "## üìã Requisiti:\n",
    "- Google Colab con GPU T4 (Runtime ‚Üí Change runtime type ‚Üí GPU)\n",
    "- Dataset LJSpeech-IT gi√† caricato su Google Drive\n",
    "- ~10GB spazio su Google Drive\n",
    "\n",
    "## ‚è±Ô∏è Tempo stimato:\n",
    "- Setup: ~10-15 min\n",
    "- Training: ~8-12 ore (1000 epoch)\n",
    "- Export: ~5 min\n",
    "\n",
    "## üéØ Risultato:\n",
    "- Modello ONNX personalizzato pronto per l'uso con Piper\n",
    "- Config JSON con impostazioni modello\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monta Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"‚úÖ Google Drive montato!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica GPU disponibile\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    vram = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"‚úÖ GPU Disponibile: {gpu_name}\")\n",
    "    print(f\"   VRAM: {vram:.1f} GB\")\n",
    "    if vram < 10:\n",
    "        print(\"   ‚ö†Ô∏è  VRAM limitata, considera di ridurre BATCH_SIZE\")\n",
    "else:\n",
    "    print(\"‚ùå GPU NON DISPONIBILE!\")\n",
    "    print(\"   Vai su Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "    raise RuntimeError(\"GPU required for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installa dipendenze sistema\n",
    "print(\"üì¶ Installazione espeak-ng...\")\n",
    "!apt-get update -qq\n",
    "!apt-get install -qq espeak-ng\n",
    "\n",
    "print(\"\\nüì¶ Installazione piper_train e dipendenze...\")\n",
    "!pip install -q piper-phonemize piper_train\n",
    "\n",
    "print(\"\\n‚úÖ Installazione completata!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Configurazione Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è CONFIGURAZIONE PERCORSI\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Percorso dataset su Google Drive (MODIFICA SE NECESSARIO)\n",
    "DATASET_DIR = \"/content/drive/MyDrive/piper_training/dataset/ljspeech_italian\"\n",
    "WAVS_DIR = os.path.join(DATASET_DIR, \"wavs\")\n",
    "METADATA_FILE = os.path.join(DATASET_DIR, \"metadata.csv\")\n",
    "\n",
    "# Percorso output training\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/piper_training/output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Verifica dataset\n",
    "if not os.path.exists(METADATA_FILE):\n",
    "    raise FileNotFoundError(f\"‚ùå metadata.csv non trovato in {DATASET_DIR}\")\n",
    "\n",
    "# Conta file audio\n",
    "wav_files = list(Path(WAVS_DIR).glob(\"*.wav\"))\n",
    "print(f\"‚úÖ Dataset trovato!\")\n",
    "print(f\"   üìÅ {len(wav_files)} file audio in {WAVS_DIR}\")\n",
    "print(f\"   üìÑ metadata.csv: {METADATA_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Preprocessing - Generazione Phonemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera phonemi con espeak-ng\n",
    "import csv\n",
    "from piper_phonemize import phonemize_espeak\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"üîÑ Generazione phonemi...\")\n",
    "\n",
    "# Leggi metadata\n",
    "metadata = []\n",
    "with open(METADATA_FILE, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('|')\n",
    "        if len(parts) == 2:\n",
    "            filename, text = parts\n",
    "            metadata.append((filename, text))\n",
    "\n",
    "print(f\"   üìä {len(metadata)} sample da processare\")\n",
    "\n",
    "# Genera phonemi per italiano\n",
    "phonemized_metadata = []\n",
    "for filename, text in tqdm(metadata, desc=\"Phonemizing\"):\n",
    "    try:\n",
    "        # Usa espeak-ng per italiano\n",
    "        phonemes = phonemize_espeak(text, voice=\"it\")[0]\n",
    "        phonemized_metadata.append((filename, text, phonemes))\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Errore su {filename}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Salva metadata con phonemi\n",
    "phonemized_file = os.path.join(DATASET_DIR, \"metadata_phonemized.csv\")\n",
    "with open(phonemized_file, 'w', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f, delimiter='|')\n",
    "    for row in phonemized_metadata:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"\\n‚úÖ Phonemi generati!\")\n",
    "print(f\"   üíæ Salvato in: {phonemized_file}\")\n",
    "print(f\"   üìä {len(phonemized_metadata)} sample processati\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Download Checkpoint Base (Fine-Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download checkpoint base italiano per fine-tuning\n",
    "import wget\n",
    "\n",
    "# Checkpoint base Piper medium-quality italiano\n",
    "# (Usare checkpoint esistente accelera training)\n",
    "CHECKPOINT_URL = \"https://huggingface.co/rhasspy/piper-voices/resolve/main/it/it_IT/riccardo/medium/it_IT-riccardo-medium.ckpt\"\n",
    "CHECKPOINT_DIR = \"/content/piper_checkpoints\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "checkpoint_path = os.path.join(CHECKPOINT_DIR, \"base_checkpoint.ckpt\")\n",
    "\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    print(\"üì• Download checkpoint base...\")\n",
    "    wget.download(CHECKPOINT_URL, checkpoint_path)\n",
    "    print(\"\\n‚úÖ Checkpoint scaricato!\")\n",
    "else:\n",
    "    print(\"‚úÖ Checkpoint gi√† presente\")\n",
    "\n",
    "print(f\"   üìÑ {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è HYPERPARAMETERS\n",
    "\n",
    "# Training\n",
    "MAX_EPOCHS = 1000        # Epoch totali (ridurre per test: 100)\n",
    "BATCH_SIZE = 8           # Ridurre a 4 se OOM\n",
    "LEARNING_RATE = 1e-4     # Learning rate\n",
    "VALIDATION_SPLIT = 0.1   # 10% validation\n",
    "\n",
    "# Checkpoint\n",
    "SAVE_EVERY = 100         # Salva checkpoint ogni N epoch\n",
    "CHECKPOINT_DIR_TRAIN = os.path.join(OUTPUT_DIR, \"checkpoints\")\n",
    "os.makedirs(CHECKPOINT_DIR_TRAIN, exist_ok=True)\n",
    "\n",
    "# Audio\n",
    "SAMPLE_RATE = 22050      # Hz\n",
    "QUALITY = \"medium\"       # low, medium, high\n",
    "\n",
    "print(\"‚öôÔ∏è  Configurazione Training:\")\n",
    "print(f\"   Max Epochs: {MAX_EPOCHS}\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"   Validation: {VALIDATION_SPLIT*100}%\")\n",
    "print(f\"   Quality: {QUALITY}\")\n",
    "print(f\"   Sample Rate: {SAMPLE_RATE} Hz\")\n",
    "print(f\"\\n   üíæ Checkpoints: {CHECKPOINT_DIR_TRAIN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Avvio Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparazione dataset per piper_train\n",
    "# Crea config.yaml per training\n",
    "\n",
    "import yaml\n",
    "\n",
    "config = {\n",
    "    \"dataset\": {\n",
    "        \"metadata_file\": phonemized_file,\n",
    "        \"audio_dir\": WAVS_DIR,\n",
    "        \"sample_rate\": SAMPLE_RATE,\n",
    "        \"validation_split\": VALIDATION_SPLIT\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"quality\": QUALITY,\n",
    "        \"language\": \"it\"\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"max_epochs\": MAX_EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"checkpoint_dir\": CHECKPOINT_DIR_TRAIN,\n",
    "        \"save_every\": SAVE_EVERY,\n",
    "        \"resume_from_checkpoint\": checkpoint_path  # Fine-tuning da checkpoint base\n",
    "    }\n",
    "}\n",
    "\n",
    "config_file = os.path.join(OUTPUT_DIR, \"training_config.yaml\")\n",
    "with open(config_file, 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(f\"‚úÖ Config salvata: {config_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVVIO TRAINING\n",
    "# ‚ö†Ô∏è Questo pu√≤ richiedere 8-12 ore!\n",
    "\n",
    "print(\"üöÄ Avvio training...\")\n",
    "print(\"‚è±Ô∏è  Tempo stimato: ~8-12 ore per 1000 epoch\")\n",
    "print(\"üí° Colab Free ha limite 12 ore ‚Üí usa checkpoints per riprendere\\n\")\n",
    "\n",
    "# Comando training piper\n",
    "!python -m piper_train \\\n",
    "    --config {config_file} \\\n",
    "    --dataset-dir {DATASET_DIR} \\\n",
    "    --output-dir {CHECKPOINT_DIR_TRAIN} \\\n",
    "    --resume-from-checkpoint {checkpoint_path}\n",
    "\n",
    "print(\"\\n‚úÖ Training completato!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Export Modello ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trova ultimo checkpoint\n",
    "import glob\n",
    "\n",
    "checkpoints = sorted(glob.glob(os.path.join(CHECKPOINT_DIR_TRAIN, \"*.ckpt\")))\n",
    "if not checkpoints:\n",
    "    raise FileNotFoundError(\"‚ùå Nessun checkpoint trovato!\")\n",
    "\n",
    "last_checkpoint = checkpoints[-1]\n",
    "print(f\"‚úÖ Ultimo checkpoint: {last_checkpoint}\")\n",
    "\n",
    "# Export a ONNX\n",
    "EXPORT_DIR = os.path.join(OUTPUT_DIR, \"final_model\")\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"\\nüîÑ Export a ONNX...\")\n",
    "!python -m piper_train.export_onnx \\\n",
    "    {last_checkpoint} \\\n",
    "    {EXPORT_DIR}/model.onnx\n",
    "\n",
    "print(f\"\\n‚úÖ Modello ONNX creato!\")\n",
    "print(f\"   üìÑ {EXPORT_DIR}/model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Test Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test generazione audio\n",
    "from IPython.display import Audio, display\n",
    "import subprocess\n",
    "\n",
    "# Download piper binary per test\n",
    "if not os.path.exists(\"/content/piper\"):\n",
    "    print(\"üì• Download Piper binary...\")\n",
    "    !wget -q https://github.com/rhasspy/piper/releases/latest/download/piper_linux_x86_64.tar.gz\n",
    "    !tar -xzf piper_linux_x86_64.tar.gz -C /content\n",
    "    print(\"‚úÖ Piper installato\")\n",
    "\n",
    "# Genera audio di test\n",
    "test_text = \"Benvenuto al sistema di prenotazioni. Questa √® una voce personalizzata creata con Piper TTS.\"\n",
    "test_output = \"/content/test_output.wav\"\n",
    "\n",
    "print(f\"üîä Generazione audio test...\")\n",
    "print(f\"   Testo: {test_text}\")\n",
    "\n",
    "# Usa piper per generare audio\n",
    "result = subprocess.run(\n",
    "    ['/content/piper/piper', \n",
    "     '--model', f'{EXPORT_DIR}/model.onnx',\n",
    "     '--output_file', test_output],\n",
    "    input=test_text.encode('utf-8'),\n",
    "    capture_output=True\n",
    ")\n",
    "\n",
    "if os.path.exists(test_output):\n",
    "    print(\"\\n‚úÖ Audio generato!\")\n",
    "    display(Audio(test_output))\n",
    "else:\n",
    "    print(f\"‚ùå Errore generazione: {result.stderr.decode()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Download Modello Finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea ZIP con modello e config per download\n",
    "import shutil\n",
    "\n",
    "zip_path = \"/content/my_piper_model.zip\"\n",
    "shutil.make_archive(\n",
    "    zip_path.replace('.zip', ''),\n",
    "    'zip',\n",
    "    EXPORT_DIR\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Modello pronto per il download!\")\n",
    "print(f\"   üì¶ {zip_path}\")\n",
    "print(\"\\nüí° Click destro sul file nel pannello Files ‚Üí Download\")\n",
    "print(\"\\nüìã Contenuto:\")\n",
    "print(\"   - model.onnx (modello TTS)\")\n",
    "print(\"   - model.onnx.json (config)\")\n",
    "\n",
    "# Mostra size\n",
    "size_mb = os.path.getsize(zip_path) / 1e6\n",
    "print(f\"\\n   üìä Dimensione: {size_mb:.1f} MB\")\n",
    "\n",
    "# Opzionale: Download automatico\n",
    "from google.colab import files\n",
    "files.download(zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Completato!\n",
    "\n",
    "### Uso del modello in locale:\n",
    "\n",
    "```bash\n",
    "# Estrai ZIP\n",
    "unzip my_piper_model.zip\n",
    "\n",
    "# Genera audio\n",
    "echo \"Testo di prova\" | ./piper/piper \\\n",
    "  --model model.onnx \\\n",
    "  --output_file output.wav\n",
    "```\n",
    "\n",
    "### Prossimi passi:\n",
    "- Testa il modello con vari testi\n",
    "- Se qualit√† non soddisfacente: aumenta MAX_EPOCHS\n",
    "- Confronta con modello base\n",
    "\n",
    "### Riprendere training (se interrotto):\n",
    "1. Riavvia runtime\n",
    "2. Ri-esegui celle 1-5\n",
    "3. Modifica cella 6: `resume_from_checkpoint` ‚Üí ultimo checkpoint salvato\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
