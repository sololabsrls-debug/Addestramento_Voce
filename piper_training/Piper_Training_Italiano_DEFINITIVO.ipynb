{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé§ PIPER TTS - TRAINING ITALIANO DEFINITIVO\n",
    "\n",
    "## üìã Panoramica\n",
    "Questo notebook addestra un modello Piper TTS in italiano usando il dataset giacomoarienti/female-LJSpeech-italian.\n",
    "\n",
    "**Caratteristiche:**\n",
    "- ‚úÖ Training completo da zero\n",
    "- ‚úÖ Dataset: 5856 file audio (8h 23m)\n",
    "- ‚úÖ Voce femminile italiana professionale\n",
    "- ‚úÖ Sample rate: 16000Hz\n",
    "- ‚è±Ô∏è Tempo stimato: 12-16 ore su GPU T4\n",
    "\n",
    "**Prerequisiti:**\n",
    "- ‚úÖ Google Colab con GPU (Runtime > Change runtime type > GPU)\n",
    "- ‚úÖ Dataset scaricato usando `Download_Dataset_Italiano_DEFINITIVO.ipynb`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß STEP 1: Verifica GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verifica che la GPU sia disponibile\n!nvidia-smi\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"‚úÖ Se vedi info GPU sopra, sei pronto!\")\nprint(\"‚ùå Se vedi errore: Runtime > Change runtime type > GPU\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ STEP 2: Monta Google Drive\n\n**IMPORTANTE:** Il dataset deve essere gi√† stato scaricato usando il notebook `Download_Dataset_Italiano_DEFINITIVO.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from google.colab import drive\n\nprint(\"üìÇ Montaggio Google Drive...\\n\")\ndrive.mount('/content/drive')\nprint(\"\\n‚úÖ Google Drive montato con successo!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ STEP 3: Installazione Piper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"üì¶ Installazione Piper Training...\\n\")\n\n# Installazione dipendenze base\n!pip install -q onnxruntime\n!pip install -q torch torchvision torchaudio\n\n# Installazione piper-phonemize dai sorgenti (pi√π affidabile)\nprint(\"üîß Installazione piper-phonemize dai sorgenti...\")\n!apt-get install -q -y build-essential\n!pip install -q pybind11\n\n# Clona e installa piper-phonemize\n!git clone https://github.com/rhasspy/piper-phonemize.git\n%cd piper-phonemize\n!pip install -q .\n%cd /content\n\nprint(\"‚úÖ piper-phonemize installato!\\n\")\n\n# Clona repository Piper\nprint(\"üì¶ Clonazione repository Piper...\")\n!git clone https://github.com/rhasspy/piper.git\n%cd piper/src/python\n\n# Installa requirements (ora dovrebbe funzionare)\n!pip install -q -r requirements.txt\n!pip install -q -e .\n\n%cd /content\nprint(\"\\n‚úÖ Installazione Piper completata!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ STEP 4: Verifica Dataset\n",
    "\n",
    "**IMPORTANTE:** Prima di eseguire questa cella, assicurati di aver scaricato il dataset usando il notebook `Download_Dataset_Italiano_DEFINITIVO.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport pandas as pd\nfrom pathlib import Path\n\n# Path dataset (scaricato dal notebook di download)\nDATASET_DIR = \"/content/drive/MyDrive/ljspeech_italian\"\nOUTPUT_DIR = \"/content/piper_output\"\n\nprint(\"=\"*60)\nprint(\"  üîç VERIFICA DATASET\")\nprint(\"=\"*60)\n\n# Verifica esistenza directory\nif not os.path.exists(DATASET_DIR):\n    print(\"\\n‚ùå ERRORE: Dataset non trovato!\")\n    print(f\"   Path cercato: {DATASET_DIR} (Google Drive)\")\n    print(\"\\nüí° SOLUZIONE:\")\n    print(\"   1. Esegui prima il notebook 'Download_Dataset_Italiano_DEFINITIVO.ipynb'\")\n    print(\"   2. Assicurati che il dataset sia in Google Drive: /content/drive/MyDrive/ljspeech_italian/\")\n    raise FileNotFoundError(f\"Dataset non trovato in {DATASET_DIR}\")\n\n# Verifica metadata.csv\nmetadata_path = f\"{DATASET_DIR}/metadata.csv\"\nif not os.path.exists(metadata_path):\n    raise FileNotFoundError(\"metadata.csv non trovato!\")\n\n# Verifica wavs/\nwavs_dir = f\"{DATASET_DIR}/wavs\"\nif not os.path.exists(wavs_dir):\n    raise FileNotFoundError(\"Cartella wavs/ non trovata!\")\n\n# Carica e verifica metadata\nmetadata = pd.read_csv(metadata_path, sep='|', header=None, names=['filename', 'text'])\nnum_metadata = len(metadata)\n\n# Conta file WAV\nwav_files = list(Path(wavs_dir).glob(\"*.wav\"))\nnum_wavs = len(wav_files)\n\nprint(f\"\\n‚úÖ Dataset trovato!\")\nprint(f\"   üìÅ Path: {DATASET_DIR}\")\nprint(f\"   üìÑ Trascrizioni: {num_metadata}\")\nprint(f\"   üéµ File audio: {num_wavs}\")\n\nif num_metadata == num_wavs:\n    print(f\"   ‚úÖ Corrispondenza perfetta!\")\nelse:\n    print(f\"   ‚ö†Ô∏è  Warning: {num_metadata} trascrizioni vs {num_wavs} file audio\")\n\n# Crea directory output\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nprint(f\"\\n‚úÖ Directory output creata: {OUTPUT_DIR}\")\n\nprint(\"\\n\" + \"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéõÔ∏è STEP 5: Configurazione Training\n",
    "\n",
    "Qui configuriamo tutti i parametri del modello e del training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\n\nprint(\"=\"*60)\nprint(\"  ‚öôÔ∏è CONFIGURAZIONE TRAINING\")\nprint(\"=\"*60)\n\n# Configurazione completa\nconfig = {\n    \"audio\": {\n        \"sample_rate\": 16000,\n        \"max_wav_value\": 32767.0,\n        \"filter_length\": 1024,\n        \"hop_length\": 256,\n        \"win_length\": 1024\n    },\n    \"model\": {\n        \"name\": \"vits\",\n        \"hidden_channels\": 192,\n        \"inter_channels\": 192,\n        \"filter_channels\": 768,\n        \"n_heads\": 2,\n        \"n_layers\": 6,\n        \"kernel_size\": 3,\n        \"p_dropout\": 0.1\n    },\n    \"training\": {\n        \"epochs\": 10000,\n        \"learning_rate\": 0.0002,\n        \"batch_size\": 16,\n        \"log_interval\": 100,\n        \"save_interval\": 1000,\n        \"num_workers\": 4\n    },\n    \"dataset\": {\n        \"path\": DATASET_DIR,\n        \"text_cleaners\": [\"basic_cleaners\"],\n        \"language\": \"it-it\"\n    }\n}\n\n# Salva configurazione\nconfig_path = f\"{OUTPUT_DIR}/config.json\"\nwith open(config_path, 'w', encoding='utf-8') as f:\n    json.dump(config, f, indent=2, ensure_ascii=False)\n\nprint(f\"\\n‚úÖ Configurazione salvata: {config_path}\")\nprint(f\"\\nüìù Parametri principali:\")\nprint(f\"   ‚Ä¢ Sample rate: {config['audio']['sample_rate']} Hz\")\nprint(f\"   ‚Ä¢ Lingua: {config['dataset']['language']} (Italiano)\")\nprint(f\"   ‚Ä¢ Epochs: {config['training']['epochs']:,}\")\nprint(f\"   ‚Ä¢ Batch size: {config['training']['batch_size']}\")\nprint(f\"   ‚Ä¢ Learning rate: {config['training']['learning_rate']}\")\nprint(f\"   ‚Ä¢ Salvataggio checkpoint ogni: {config['training']['save_interval']} steps\")\n\nprint(\"\\n\" + \"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ STEP 6: Preprocessing Dataset\n",
    "\n",
    "Prepara il dataset per il training (estrazione features, phonemization, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*60)\nprint(\"  üîÑ PREPROCESSING DATASET\")\nprint(\"=\"*60)\nprint(\"\\n‚è±Ô∏è  Questo pu√≤ richiedere 10-20 minuti...\\n\")\n\nPREPROCESSED_DIR = f\"{OUTPUT_DIR}/preprocessed\"\n\n!python /content/piper/src/python/piper_train/preprocess.py \\\n    --input-dir {DATASET_DIR} \\\n    --output-dir {PREPROCESSED_DIR} \\\n    --language it-it \\\n    --sample-rate 16000\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"‚úÖ Preprocessing completato!\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ STEP 7: AVVIO TRAINING\n",
    "\n",
    "**‚ö†Ô∏è ATTENZIONE:** Il training richieder√† **12-16 ore** su GPU T4.\n",
    "\n",
    "**Consigli:**\n",
    "- üí° Tieni aperta la tab del browser per evitare disconnessioni\n",
    "- üí° Il training salva checkpoint ogni 1000 step, quindi puoi riprenderlo se si interrompe\n",
    "- üí° Puoi monitorare i log per vedere i progressi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*60)\nprint(\"  üéØ AVVIO TRAINING\")\nprint(\"=\"*60)\nprint(\"\\n‚è±Ô∏è  Tempo stimato: 12-16 ore\")\nprint(\"üíæ Checkpoint salvati ogni 1000 step\")\nprint(\"üìä Log ogni 100 step\\n\")\nprint(\"-\"*60)\n\nCHECKPOINT_DIR = f\"{OUTPUT_DIR}/checkpoints\"\n\n%cd /content/piper/src/python\n\n!python -m piper_train \\\n    --dataset-dir {PREPROCESSED_DIR} \\\n    --output-dir {CHECKPOINT_DIR} \\\n    --config {config_path} \\\n    --restore-checkpoint\n\n%cd /content\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"üéâ TRAINING COMPLETATO!\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä STEP 8: Verifica Checkpoint\n",
    "\n",
    "Visualizza i checkpoint salvati durante il training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import glob\n\nprint(\"=\"*60)\nprint(\"  üìä CHECKPOINT SALVATI\")\nprint(\"=\"*60)\n\ncheckpoints = sorted(glob.glob(f\"{CHECKPOINT_DIR}/*.pt\"))\n\nif len(checkpoints) == 0:\n    print(\"\\n‚ùå Nessun checkpoint trovato!\")\nelse:\n    print(f\"\\n‚úÖ Trovati {len(checkpoints)} checkpoint:\\n\")\n    \n    for ckpt in checkpoints[-10:]:  # Mostra ultimi 10\n        size_mb = os.path.getsize(ckpt) / (1024*1024)\n        print(f\"   üìÅ {os.path.basename(ckpt)} ({size_mb:.1f} MB)\")\n    \n    if len(checkpoints) > 10:\n        print(f\"\\n   ... e altri {len(checkpoints)-10} checkpoint\")\n\nprint(\"\\n\" + \"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéµ STEP 9: Export Modello ONNX\n",
    "\n",
    "Converte il checkpoint PyTorch in formato ONNX (richiesto da Piper per l'inferenza)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import glob\n\nprint(\"=\"*60)\nprint(\"  üì¶ EXPORT MODELLO ONNX\")\nprint(\"=\"*60)\n\n# Trova ultimo checkpoint\ncheckpoints = sorted(glob.glob(f\"{CHECKPOINT_DIR}/*.pt\"))\n\nif len(checkpoints) == 0:\n    print(\"\\n‚ùå Nessun checkpoint trovato!\")\n    print(\"Assicurati che il training sia completato.\")\nelse:\n    latest_checkpoint = checkpoints[-1]\n    print(f\"\\nüìÅ Usando checkpoint: {os.path.basename(latest_checkpoint)}\")\n    \n    model_output = f\"{OUTPUT_DIR}/model.onnx\"\n    \n    %cd /content/piper/src/python\n    \n    !python -m piper_train.export_onnx \\\n        {latest_checkpoint} \\\n        {model_output}\n    \n    %cd /content\n    \n    if os.path.exists(model_output):\n        size_mb = os.path.getsize(model_output) / (1024*1024)\n        print(f\"\\n‚úÖ Modello esportato con successo!\")\n        print(f\"   üìÅ Path: {model_output}\")\n        print(f\"   üíæ Dimensione: {size_mb:.1f} MB\")\n    else:\n        print(\"\\n‚ùå Errore durante l'export!\")\n\nprint(\"\\n\" + \"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ STEP 10: Test Modello\n",
    "\n",
    "Prova il modello generando audio da testo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from IPython.display import Audio, display\nimport subprocess\nimport os\n\nprint(\"=\"*60)\nprint(\"  üß™ TEST MODELLO\")\nprint(\"=\"*60)\n\n# Testi di test in italiano\ntest_texts = [\n    \"Buongiorno, questo √® un test del modello Piper addestrato in italiano.\",\n    \"La sintesi vocale funziona correttamente con frasi pi√π lunghe e complesse.\",\n    \"I Malavoglia √® un romanzo di Giovanni Verga.\"\n]\n\nmodel_path = f\"{OUTPUT_DIR}/model.onnx\"\n\nif not os.path.exists(model_path):\n    print(\"\\n‚ùå Modello non trovato! Esegui prima lo STEP 8.\")\nelse:\n    print(\"\\nüé§ Generazione audio di test...\\n\")\n    \n    for i, text in enumerate(test_texts, 1):\n        output_wav = f\"{OUTPUT_DIR}/test_{i}.wav\"\n        \n        print(f\"{i}. Testo: \\\"{text}\\\"\")\n        \n        # Genera audio con Piper\n        result = subprocess.run(\n            [\"piper\", \"--model\", model_path, \"--output_file\", output_wav],\n            input=text.encode('utf-8'),\n            capture_output=True\n        )\n        \n        if os.path.exists(output_wav):\n            print(f\"   ‚úÖ Audio generato: {output_wav}\")\n            display(Audio(output_wav))\n            print()\n        else:\n            print(f\"   ‚ùå Errore nella generazione\")\n            if result.stderr:\n                print(f\"   Errore: {result.stderr.decode('utf-8')}\")\n\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ STEP 11: Download Modello\n",
    "\n",
    "Scarica il modello finale sul tuo computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import shutil\nfrom google.colab import files\n\nprint(\"=\"*60)\nprint(\"  üíæ DOWNLOAD MODELLO\")\nprint(\"=\"*60)\n\nmodel_path = f\"{OUTPUT_DIR}/model.onnx\"\n\nif not os.path.exists(model_path):\n    print(\"\\n‚ùå Modello non trovato!\")\nelse:\n    print(\"\\nüì¶ Creazione archivio per il download...\\n\")\n    \n    # Crea directory per il package\n    package_dir = f\"{OUTPUT_DIR}/piper_model_italiano\"\n    os.makedirs(package_dir, exist_ok=True)\n    \n    # Copia file necessari\n    shutil.copy(model_path, package_dir)\n    shutil.copy(config_path, package_dir)\n    \n    # Crea README\n    readme_content = f\"\"\"# Piper TTS - Modello Italiano\n\n## Informazioni Modello\n- **Lingua**: Italiano (it-it)\n- **Voce**: Femminile\n- **Dataset**: giacomoarienti/female-LJSpeech-italian\n- **Sample Rate**: 16000 Hz\n- **Ore di training**: ~8h 23m di audio\n\n## Utilizzo\n```bash\necho \"Ciao, questo √® un test\" | piper --model model.onnx --output_file output.wav\n```\n\n## File Inclusi\n- `model.onnx`: Modello ONNX per l'inferenza\n- `config.json`: Configurazione del modello\n\"\"\"\n    \n    with open(f\"{package_dir}/README.md\", 'w', encoding='utf-8') as f:\n        f.write(readme_content)\n    \n    # Crea ZIP\n    archive_path = shutil.make_archive(\n        f\"{OUTPUT_DIR}/piper_model_italiano\",\n        'zip',\n        package_dir\n    )\n    \n    archive_size_mb = os.path.getsize(archive_path) / (1024*1024)\n    \n    print(f\"‚úÖ Archivio creato:\")\n    print(f\"   üìÅ {os.path.basename(archive_path)}\")\n    print(f\"   üíæ Dimensione: {archive_size_mb:.1f} MB\")\n    print(f\"\\nüì• Download in corso...\\n\")\n    \n    # Download\n    files.download(archive_path)\n    \n    print(\"\\n‚úÖ Download completato!\")\n\nprint(\"\\n\" + \"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ COMPLETATO!\n",
    "\n",
    "### Risultati:\n",
    "- ‚úÖ Modello Piper TTS italiano addestrato\n",
    "- ‚úÖ File ONNX pronto per l'uso\n",
    "- ‚úÖ Configurazione salvata\n",
    "\n",
    "### Prossimi Passi:\n",
    "1. **Testa il modello** con frasi diverse\n",
    "2. **Fine-tuning** se necessario con pi√π dati\n",
    "3. **Integra** in applicazioni usando Piper CLI\n",
    "\n",
    "### Utilizzo del Modello:\n",
    "```bash\n",
    "# Sintesi da testo\n",
    "echo \"Buongiorno, come stai?\" | piper --model model.onnx --output_file output.wav\n",
    "\n",
    "# Da file di testo\n",
    "cat testo.txt | piper --model model.onnx --output_file output.wav\n",
    "```\n",
    "\n",
    "### Troubleshooting:\n",
    "- **Qualit√† audio bassa**: Aumenta epochs o migliora dataset\n",
    "- **OOM Error**: Riduci batch_size nella configurazione\n",
    "- **Training interrotto**: Riavvia dalla cella STEP 6 (riprender√† dall'ultimo checkpoint)\n",
    "\n",
    "### Risorse:\n",
    "- [Piper GitHub](https://github.com/rhasspy/piper)\n",
    "- [Piper Documentation](https://github.com/rhasspy/piper/blob/master/README.md)\n",
    "\n",
    "---\n",
    "\n",
    "**Buon TTS! üé§üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}