# ğŸ™ï¸ Piper TTS - Fine-Tuning per Italiano

Progetto per il fine-tuning di modelli Piper TTS con voci italiane personalizzate.

## ğŸš€ Quick Start

### **Fine-Tuning su Google Colab** (Raccomandato)

Il modo piÃ¹ semplice e veloce per fare fine-tuning di Piper:

1. **Apri il Notebook su Colab:**
   - Carica `Piper_FineTuning_Colab.ipynb` su https://colab.research.google.com

2. **Attiva GPU:**
   - Runtime â†’ Change runtime type â†’ GPU (T4)

3. **Esegui il Training:**
   - Segui le celle del notebook in ordine
   - Il dataset verrÃ  scaricato automaticamente
   - Training: ~8-12 ore per fine-tuning

4. **Download Modello:**
   - Il modello finale sarÃ  disponibile per il download
   - Compatibile con Piper TTS

## ğŸ“Š Dataset

Il notebook utilizza il dataset **LJSpeech-IT** (giacomoarienti/female-LJSpeech-italian):
- **5,856 campioni audio**
- **~10-11 ore** di parlato
- **Voce femminile** italiana
- **QualitÃ  media-alta**

## ğŸ¯ Modelli Piper

Piper supporta diverse qualitÃ  di modelli:
- **x_low**: QualitÃ  bassa, veloce
- **low**: QualitÃ  medio-bassa
- **medium**: QualitÃ  media (consigliato)
- **high**: QualitÃ  alta (richiede piÃ¹ risorse)

## ğŸ“ Struttura Progetto

```
piper-tts-finetuning/
â”œâ”€â”€ Piper_FineTuning_Colab.ipynb    # Notebook training completo
â”œâ”€â”€ README.md                        # Questa guida
â””â”€â”€ requirements.txt                 # Dipendenze (opzionale, per uso locale)
```

## ğŸ’» Uso Locale (Opzionale)

Se vuoi usare Piper localmente dopo il training:

### Installazione

```bash
# Download Piper (Windows)
wget https://github.com/rhasspy/piper/releases/latest/download/piper_windows_amd64.zip
unzip piper_windows_amd64.zip

# Linux/Mac
wget https://github.com/rhasspy/piper/releases/latest/download/piper_amd64.tar.gz
tar -xzf piper_amd64.tar.gz
```

### Generazione Audio

```bash
# Con il tuo modello custom
echo "Questo Ã¨ un test" | ./piper/piper \
  --model ./tuo_modello.onnx \
  --output_file output.wav
```

## ğŸ”§ Requisiti

### Per Colab (Consigliato):
- Google account
- GPU T4 (gratis su Colab)
- ~10GB spazio Drive

### Per Training Locale:
- Python 3.9-3.11
- GPU NVIDIA con CUDA (24GB VRAM consigliati)
- PyTorch
- `piper_train` package

## ğŸ“– Risorse

- **Piper TTS**: https://github.com/rhasspy/piper
- **Piper Training Docs**: https://github.com/rhasspy/piper/blob/master/TRAINING.md
- **Dataset LJSpeech-IT**: https://huggingface.co/datasets/giacomoarienti/female-LJSpeech-italian
- **Modelli Pre-addestrati**: https://huggingface.co/rhasspy/piper-voices

## âš™ï¸ Parametri Training Consigliati

```python
# Fine-tuning (da modello esistente)
MAX_EPOCHS = 1000
BATCH_SIZE = 8  # Riduci se OOM
QUALITY = "medium"
SAMPLE_RATE = 22050

# Training da zero (non consigliato senza dataset grande)
MAX_EPOCHS = 2000
DATASET_SIZE = "13,000+ campioni"
```

## ğŸ“ Processo Fine-Tuning

1. **Preprocessing** (~10-30 min)
   - Download dataset
   - Conversione audio in formato corretto
   - Generazione phonemi con espeak-ng

2. **Training** (~8-12 ore per fine-tuning)
   - Caricamento checkpoint base
   - Training con GPU T4
   - Salvataggio checkpoints ogni 100 epoch

3. **Export** (~5 min)
   - Conversione checkpoint â†’ ONNX
   - Generazione config.json
   - Test audio

4. **Download** (~2 min)
   - Download modello.onnx
   - Download modello.onnx.json
   - Pronto per l'uso!

## ğŸ“ Note

- **Colab Free**: Limite 12 ore â†’ Usa checkpoints per riprendere
- **Colab Pro** (â‚¬10/mese): 24 ore, GPU migliori
- **Real-Time Factor**: Piper Ã¨ molto veloce (~0.1 RTF = 10x real-time)
- **QualitÃ **: Fine-tuning produce risultati migliori di training da zero con dataset piccoli

## ğŸ› Troubleshooting

### Out of Memory su Colab
```python
# Riduci batch size nel notebook
BATCH_SIZE = 4  # invece di 8
```

### Training troppo lento
```python
# Verifica GPU attiva
import torch
print(torch.cuda.is_available())  # Deve essere True
```

### Modello finale robotico
- Aumenta epoch di training
- Verifica qualitÃ  dataset (audio pulito?)
- Prova fine-tuning invece di training da zero

## ğŸ“„ Licenza

Questo progetto: MIT License

**Modelli e Dataset:**
- Piper TTS: MIT License âœ… Commerciale OK
- LJSpeech-IT: Apache 2.0 âœ… Commerciale OK

---

## ğŸ‰ Credits

- **Piper TTS**: https://github.com/rhasspy/piper (Rhasspy team)
- **LJSpeech-IT Dataset**: giacomoarienti (Hugging Face)
- **Training Framework**: PyTorch + Lightning

---

**Buon fine-tuning! ğŸš€**
