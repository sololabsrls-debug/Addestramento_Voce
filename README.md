# ğŸ™ï¸ Piper TTS - Training & Fine-Tuning

Progetto per training e fine-tuning di modelli Piper TTS con voci personalizzate.

## ğŸš€ Quick Start

Scegli il percorso piÃ¹ adatto a te:

### **Percorso 1: Fine-Tuning Veloce** âš¡ (Raccomandato per iniziare)

Adatta un modello esistente con il tuo dataset (30+ minuti di audio).

1. **Apri:** `piper_training/Piper_FineTuning_Colab.ipynb`
2. **Upload su Colab:** https://colab.research.google.com
3. **Attiva GPU:** Runtime â†’ Change runtime type â†’ GPU (T4)
4. **Esegui:** Run all
5. **Tempo:** ~8-12 ore

### **Percorso 2: Training Completo** ğŸ¯ (Per massima qualitÃ )

Addestra un modello da zero (2+ ore di audio consigliato).

1. **Apri:** `piper_training/Piper_Training_Complete.ipynb`
2. **Upload su Colab:** https://colab.research.google.com
3. **Attiva GPU:** Runtime â†’ Change runtime type â†’ GPU (T4)
4. **Esegui:** Run all
5. **Tempo:** ~12-16 ore

### **Guide Disponibili**

- ğŸ“– **Guida Completa:** `piper_training/PIPER_TRAINING_GUIDE.md` - Tutto quello che devi sapere
- âš¡ **Quick Start:** `piper_training/PIPER_QUICK_START.md` - Inizia in 2 passi

## ğŸ“Š Dataset

Il notebook utilizza il dataset **LJSpeech-IT** (giacomoarienti/female-LJSpeech-italian):
- **5,856 campioni audio**
- **~10-11 ore** di parlato
- **Voce femminile** italiana
- **QualitÃ  media-alta**

## ğŸ¯ Modelli Piper

Piper supporta diverse qualitÃ  di modelli:
- **x_low**: QualitÃ  bassa, veloce
- **low**: QualitÃ  medio-bassa
- **medium**: QualitÃ  media (consigliato)
- **high**: QualitÃ  alta (richiede piÃ¹ risorse)

## ğŸ“ Struttura Progetto

```
Addestramento_Voce/
â”œâ”€â”€ piper_training/                           # ğŸ“ Tutto per il training
â”‚   â”œâ”€â”€ Piper_FineTuning_Colab.ipynb         # Fine-tuning veloce (8-12h)
â”‚   â”œâ”€â”€ Piper_Training_Complete.ipynb        # Training completo (12-16h)
â”‚   â”œâ”€â”€ PIPER_TRAINING_GUIDE.md              # Guida completa con troubleshooting
â”‚   â””â”€â”€ PIPER_QUICK_START.md                 # Quick start 2-step
â”œâ”€â”€ piper/                                    # Binari Piper (generati)
â”œâ”€â”€ scripts/                                  # Script utility
â”œâ”€â”€ README.md                                 # Questa guida
â””â”€â”€ requirements.txt                          # Dipendenze Python
```

## ğŸ’» Uso Locale (Opzionale)

Se vuoi usare Piper localmente dopo il training:

### Installazione

```bash
# Download Piper (Windows)
wget https://github.com/rhasspy/piper/releases/latest/download/piper_windows_amd64.zip
unzip piper_windows_amd64.zip

# Linux/Mac
wget https://github.com/rhasspy/piper/releases/latest/download/piper_amd64.tar.gz
tar -xzf piper_amd64.tar.gz
```

### Generazione Audio

```bash
# Con il tuo modello custom
echo "Questo Ã¨ un test" | ./piper/piper \
  --model ./tuo_modello.onnx \
  --output_file output.wav
```

## ğŸ”§ Requisiti

### Per Colab (Consigliato):
- Google account
- GPU T4 (gratis su Colab)
- ~10GB spazio Drive

### Per Training Locale:
- Python 3.9-3.11
- GPU NVIDIA con CUDA (24GB VRAM consigliati)
- PyTorch
- `piper_train` package

## ğŸ“– Risorse

- **Piper TTS**: https://github.com/rhasspy/piper
- **Piper Training Docs**: https://github.com/rhasspy/piper/blob/master/TRAINING.md
- **Dataset LJSpeech-IT**: https://huggingface.co/datasets/giacomoarienti/female-LJSpeech-italian
- **Modelli Pre-addestrati**: https://huggingface.co/rhasspy/piper-voices

## âš™ï¸ Parametri Training Consigliati

```python
# Fine-tuning (da modello esistente)
MAX_EPOCHS = 1000
BATCH_SIZE = 8  # Riduci se OOM
QUALITY = "medium"
SAMPLE_RATE = 22050

# Training da zero (non consigliato senza dataset grande)
MAX_EPOCHS = 2000
DATASET_SIZE = "13,000+ campioni"
```

## ğŸ“ Processo Fine-Tuning

1. **Preprocessing** (~10-30 min)
   - Download dataset
   - Conversione audio in formato corretto
   - Generazione phonemi con espeak-ng

2. **Training** (~8-12 ore per fine-tuning)
   - Caricamento checkpoint base
   - Training con GPU T4
   - Salvataggio checkpoints ogni 100 epoch

3. **Export** (~5 min)
   - Conversione checkpoint â†’ ONNX
   - Generazione config.json
   - Test audio

4. **Download** (~2 min)
   - Download modello.onnx
   - Download modello.onnx.json
   - Pronto per l'uso!

## ğŸ“ Note

- **Colab Free**: Limite 12 ore â†’ Usa checkpoints per riprendere
- **Colab Pro** (â‚¬10/mese): 24 ore, GPU migliori
- **Real-Time Factor**: Piper Ã¨ molto veloce (~0.1 RTF = 10x real-time)
- **QualitÃ **: Fine-tuning produce risultati migliori di training da zero con dataset piccoli

## ğŸ› Troubleshooting

### Out of Memory su Colab
```python
# Riduci batch size nel notebook
BATCH_SIZE = 4  # invece di 8
```

### Training troppo lento
```python
# Verifica GPU attiva
import torch
print(torch.cuda.is_available())  # Deve essere True
```

### Modello finale robotico
- Aumenta epoch di training
- Verifica qualitÃ  dataset (audio pulito?)
- Prova fine-tuning invece di training da zero

## ğŸ“„ Licenza

Questo progetto: MIT License

**Modelli e Dataset:**
- Piper TTS: MIT License âœ… Commerciale OK
- LJSpeech-IT: Apache 2.0 âœ… Commerciale OK

---

## ğŸ‰ Credits

- **Piper TTS**: https://github.com/rhasspy/piper (Rhasspy team)
- **LJSpeech-IT Dataset**: giacomoarienti (Hugging Face)
- **Training Framework**: PyTorch + Lightning

---

**Buon fine-tuning! ğŸš€**
